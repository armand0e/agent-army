# DESIGN DOCUMENT: Inter-`open-codex`-Operation Context Sharing

## 1. Overview

This document details the mechanisms for sharing context and passing data between sequential `open-codex`-like operations (hereafter "operations") that are orchestrated by the `OpenHands` Orchestrator Agent. These operations are executed by the `open_codex_lib` within temporary, isolated subdirectories inside the main `OpenHands` workspace. Effective context sharing is crucial for enabling complex, multi-step "flows" where the output of one operation informs the input of another.

## 2. Core Principles

*   **Orchestrator-Managed:** The `OpenHands` Orchestrator Agent is primarily responsible for managing the flow of context between operations.
*   **File-Based Exchange:** The primary method for passing context (especially code, large data, or structured results) will be through files written to and read from the `OpenHands` workspace.
*   **Isolation via Temporary Directories:** Each operation runs in its own temporary subdirectory (e.g., `/workspace/<orchestrator_task_id>/<step_id>/`) to prevent accidental interference. The Orchestrator explicitly moves or references data between these directories.
*   **Structured Data for Status/Metadata:** JSON files will be used for operations to report status and for the Orchestrator to pass structured metadata or small pieces of data if not suitable for direct file content.
*   **Explicit Dependencies:** The "flow" or plan generated by the Orchestrator's initial LLM call must define explicit dependencies, indicating which operation's output feeds into which subsequent operation's input.

## 3. Mechanisms for Context Sharing

### 3.1. File System Operations (Primary)

*   **Scenario:** Output of Operation A (e.g., a modified source code file) is needed by Operation B.
*   **Mechanism:**
    1.  Operation A, executed by `open_codex_lib` in its directory (e.g., `/workspace/task123/stepA_modify/`), writes its output to its `output/` subdirectory (e.g., `output/modified_code.py`).
    2.  The `OpenHands` Orchestrator Agent, after Operation A completes successfully, identifies that Operation B requires `modified_code.py`.
    3.  Before starting Operation B, the Orchestrator copies or moves `modified_code.py` from `/workspace/task123/stepA_modify/output/` to the `input/` subdirectory of Operation B (e.g., `/workspace/task123/stepB_analyze/input/modified_code.py`).
    4.  The Orchestrator then updates the `open_codex_instructions.md` for Operation B to point to the correct input file path within its own directory.
*   **Data Types:** Source code files, text files, JSON/YAML data files, generated images, logs, etc.

### 3.2. Structured Data Files (JSON for metadata, small data payloads)

*   **Scenario:** Operation A produces a small piece of structured data (e.g., a list of function names, a boolean status, a summary string) needed by Operation B.
*   **Mechanism:**
    1.  Operation A writes this structured data to a predefined JSON file in its `output/` directory (e.g., `output/result_meta.json`).
        ```json
        // Example output/result_meta.json from Operation A
        {
            "status": "success",
            "extracted_function_names": ["func1", "func2"],
            "line_count": 150
        }
        ```
    2.  The Orchestrator Agent reads this `result_meta.json`.
    3.  When preparing for Operation B, the Orchestrator can:
        *   Pass specific values from this JSON as parameters within Operation B's `open_codex_instructions.md`.
        *   Copy the entire `result_meta.json` (or relevant parts) to Operation B's `input/` directory for it to consume.
*   **Use Cases:** Passing status, small analytical results, parameters for subsequent operations.

### 3.3. `open_codex_instructions.md`

*   **Scenario:** Providing specific instructions, file paths, or small textual context to an operation.
*   **Mechanism:** The Orchestrator Agent dynamically generates this Markdown file for each operation in its respective temporary directory.
*   **Content Example for an operation that modifies a function:**
    ```markdown
    # Operation: Modify Function

    **Goal:** Refactor the function `calculate_sum` in the input file `source_code.py`.
    **Input File:** `./input/source_code.py`
    **Output File:** `./output/modified_source_code.py`

    **Instructions for LLM (to be used by open_codex_lib):**
    - The function `calculate_sum` should be updated to handle potential `TypeError` exceptions if inputs are not numbers.
    - Add a docstring explaining its functionality.
    - Ensure the core summation logic remains correct.
    - Return the entire modified file content.
    ```
*   This file itself is a key part of context provisioning.

### 3.4. Environment Variables (Limited Use)

*   **Scenario:** Passing very simple, global-like settings to `open_codex_lib` if needed, though generally less preferred than explicit instruction files for traceability.
*   **Mechanism:** The `OpenHands` agent (Orchestrator) might have the ability to set environment variables for the shell commands it executes if `open_codex_lib` is invoked as a CLI tool. If `open_codex_lib` is a Python library, parameters are passed directly.
*   **Likely not the primary method** for inter-operation context.

## 4. Role of the `OpenHands` Orchestrator Agent

The Orchestrator is central to managing context:

*   **Flow Definition:** Its initial LLM call defines the sequence of operations and their explicit input/output dependencies.
*   **Data Staging:** It is responsible for copying/moving files (outputs of one operation to inputs of next) between the isolated temporary directories of each operation.
*   **Instruction Generation:** It creates the `open_codex_instructions.md` for each operation, embedding necessary file paths and parameters derived from previous steps or the overall plan.
*   **State Aggregation:** It collects status and key outputs from each operation (e.g., from `status.json` or `result_meta.json`) to inform the overall flow and for final reporting.

## 5. Maintaining Clarity and Avoiding Conflicts

*   **Isolated Directories:** Each `open-codex` operation (a step in the flow) runs within its own unique temporary subdirectory (e.g., `/workspace/<orchestrator_task_id>/<step_name_or_id>/`). This is the primary mechanism to prevent file overwrites or conflicts between concurrent or sequential operations within the same overall task.
*   **Explicit Naming Conventions:** The Orchestrator should use clear and predictable naming for files it stages as inputs for operations.
*   **Clean-up:** The Orchestrator should ideally clean up temporary operation subdirectories after their outputs have been consumed or archived, or at the end of the entire flow, to manage workspace clutter. `OpenHands` might also have its own workspace lifecycle management.

## 6. Example Context Passing Flow

Consider a task: "Read `old_script.py`, refactor function `foo`, then write it to `new_script.py`."

**Orchestrator's Plan (Conceptual):**
1.  `op1_read`: Reads `old_script.py` from user's provided path into workspace. Output: `op1_read/output/content.txt`.
2.  `op2_refactor`: Needs `op1_read/output/content.txt`. Refactors `foo`. Output: `op2_refactor/output/refactored_content.txt`.
3.  `op3_write`: Needs `op2_refactor/output/refactored_content.txt`. Writes to `new_script.py` in a final output area.

**Orchestrator Actions & Context Management:**

1.  **Trigger `op1_read`:**
    *   Creates `/workspace/task_XYZ/op1_read/`.
    *   Writes `instructions.md`: "Goal: Read `/user_code/old_script.py` (assuming path mapping from OpenHands config) and place its content into `./output/content.txt`."
    *   `open_codex_lib` (for `op1_read`) executes, creates `/workspace/task_XYZ/op1_read/output/content.txt`.
2.  **Prepare for `op2_refactor`:**
    *   Creates `/workspace/task_XYZ/op2_refactor/input/`.
    *   Copies `/workspace/task_XYZ/op1_read/output/content.txt` to `/workspace/task_XYZ/op2_refactor/input/code_to_refactor.py`.
3.  **Trigger `op2_refactor`:**
    *   Writes `instructions.md` in `/workspace/task_XYZ/op2_refactor/`: "Goal: Refactor function `foo` in `./input/code_to_refactor.py`. Output modified code to `./output/refactored_content.txt`."
    *   `open_codex_lib` executes, creates `/workspace/task_XYZ/op2_refactor/output/refactored_content.txt`.
4.  **Prepare for `op3_write`:**
    *   Creates `/workspace/task_XYZ/op3_write/input/`.
    *   Copies `/workspace/task_XYZ/op2_refactor/output/refactored_content.txt` to `/workspace/task_XYZ/op3_write/input/final_content.txt`.
5.  **Trigger `op3_write`:**
    *   Writes `instructions.md`: "Goal: Write content from `./input/final_content.txt` to `/workspace/task_XYZ/final_output/new_script.py`."
    *   `open_cod_lib` executes.
6.  **Orchestrator collects results** from `/workspace/task_XYZ/final_output/`.

## 7. Conclusion

Inter-`open-codex`-operation context sharing within the `OpenHands` environment will be primarily file-based, managed explicitly by the `OpenHands` Orchestrator Agent. This involves careful staging of input/output files between isolated temporary directories for each operation, guided by a pre-defined flow plan and detailed instruction files. This approach ensures clarity, minimizes interference, and allows for complex multi-step tasks to be performed reliably.
